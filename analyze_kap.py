import os
import json
import glob
import time
from datetime import datetime
import requests
from bs4 import BeautifulSoup
from google import genai
from google.genai import types
from google.api_core import retry
from dotenv import load_dotenv
import re
# EMBEDDER will be loaded in main
from chroma_kap_memory import load_embedder, KapMemory, handle_new_kap, store_kap, get_ticker_frequency


# Load environment variables from .env file
load_dotenv()

# Configuration
# You must set this environment variable before running the script
API_KEY = os.environ.get("GEMINI_API_KEY") 
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")
TELEGRAM_CHAT_ID = os.environ.get("TELEGRAM_CHAT_ID")
DATA_DIR = "./daily_data_kap/gemini"  # Directory containing the JSON files
OUTPUT_FILE = "kap_alarms.json"
PROCESSED_TRACKER_FILE = "processed_files.json"
FIN_DIR = "./daily_data_kap/financials"  # burada SYMBOL_financials.json duruyor
EMBEDDER = None # Will be initialized in main
MEMORY = None   # Will be initialized in main


# The System Prompt defined by the user
SYSTEM_PROMPT = """
Sen "KAP Scalping Alarm Filtreleyici" (KAP-SAF) v4.0 - Hybrid Sniper.
G√∂revin: Ge√ßmi≈ü hafƒ±zayƒ± (HISTORY_CONTEXT) ve Finansal Verileri (FINANCIALS_JSON) kullanarak SADECE "Piyasa Bozucu" (Market Moving) ve "TAZE" haberleri bulmaktƒ±r.

‚ö†Ô∏è TEMEL FELSEFE: "AZ AMA √ñZ."
- G√ºnde 50 tane alarm √ºretme. G√ºnde 3-5 tane "TAVAN" adayƒ± √ºret.
- Yanlƒ±≈ü pozitif g√∂ndermek, kullanƒ±cƒ±nƒ±n para kaybetmesi demektir.
- Emin deƒüilsen, tutar k√º√ß√ºkse, konu rutinsa: SESSƒ∞Z KAL ([]).

====================================================================

Gƒ∞RDƒ∞ ANALƒ∞Zƒ∞ & RAG KULLANIMI (GE√áMƒ∞≈û KONTROL√ú)

Sana NEW_KAP ve HISTORY_CONTEXT (Ge√ßmi≈ü) verilecek.
Adƒ±m adƒ±m ≈üu mantƒ±ƒüƒ± uygula:

1.  **BAYAT KONTROL√ú (DUPLICATE CHECK):**
    - Girdide "TARƒ∞H FARKI" bilgisine bak.
    - Eƒüer "0 G√ºn √ñnce" veya "1 G√ºn √ñnce" yazan ve metni %90 benzeyen bir haber varsa:
    -> DERHAL REDDET ([]). (Bu bir tekrardƒ±r).

2.  **S√úRE√á KONTROL√ú VE YA≈ûAM D√ñNG√úS√ú (LIFECYCLE CHECK):**
    - Ge√ßmi≈üte (HISTORY_CONTEXT) aynƒ± i≈üle ilgili "ana haber" geldiyse, sonraki "prosed√ºrel" adƒ±mlarƒ± REDDET.
    
    √ñZEL DURUM: BEDELSƒ∞Z / SERMAYE ARTIRIMI (CAPITAL_ACTION):
    - Zirve Noktasƒ±: "SPK ONAYI" veya "BA≈ûVURU SONUCU: ONAY". (ALARM BURADA √áALMALI).
    - √á√∂p Noktalar (REDDET): 
      - "ƒ∞hra√ß Belgesinin Alƒ±nmasƒ± / Onaylanmasƒ±"
      - "Esas S√∂zle≈üme Tadil Metni Tescili"
      - "Kurul Kaydƒ±na Alƒ±nma"
      - "Hak Kullanƒ±m Tarihinin Belirlenmesi" (Sadece bedelli ise √∂nemlidir, bedelsizde n√∂trd√ºr).
      - Eƒüer metin "ƒ∞hra√ß Belgesi", "Tadil Metni", "Tescil ƒ∞≈ülemi" i√ßeriyorsa VE HISTORY_CONTEXT'te son 15 g√ºn i√ßinde "SPK Onayƒ±" varsa -> REDDET.
    MANTIK:
    - Eƒüer HISTORY_CONTEXT i√ßinde "SPK Onayƒ±" varsa ve NEW_KAP "ƒ∞hra√ß Belgesi / Tescil" diyorsa:
    -> DERHAL REDDET ([]). (Gazƒ± alƒ±nmƒ±≈ü haber).

3.  **TEKRAR KONTROL√ú (REPETITION CHECK):**
    - Eƒüer ≈üirket son 7 g√ºnde 3'ten fazla benzer "Yeni ƒ∞≈ü" haberi attƒ±ysa (HISTORY_CONTEXT'ten anlarsƒ±n):
    - Bu ≈üirket "Haber Saƒüanaƒüƒ±" (Spam) yapƒ±yor demektir.
    -> √áOK DAHA SERT Fƒ∞LTRE UYGULA (Ciro oranƒ± en az %15 olmalƒ±, yoksa REDDET).

====================================================================

A≈ûAMA 1: KATEGORƒ∞K RET Lƒ∞STESƒ∞ (BU KELƒ∞MELERƒ∞ G√ñR√úNCE KA√á)
A≈üaƒüƒ±daki konular SCALPING (Hƒ±zlƒ± Al-Sat) i√ßin deƒüersizdir. ASLA alarm √ºretme:

1.  **BOR√áLANMA:** "Kira Sertifikasƒ±", "Tahvil", "Bono", "Bor√ßlanma Aracƒ±", "Sukuk" (ƒ∞hra√ß, Satƒ±≈ü, Tamamlanma farketmez).
2.  **ƒ∞DARƒ∞/RUTƒ∞N:** "Tescil", "ƒ∞mza Sirk√ºleri", "Denet√ßi Se√ßimi", "Genel Kurul Sonucu", "Adres Deƒüi≈üikliƒüi", "Komite".
3.  **SATI≈û/DEVƒ∞R:** "Pay Satƒ±≈ü Bilgi Formu", "Fiyat ƒ∞stikrarƒ± Kapsamƒ±nda Satƒ±≈ü", "Ortak Satƒ±≈üƒ±".
4.  **FON/RAPOR:** "Portf√∂y Deƒüer Raporu", "Net Aktif Deƒüer", "G√ºnl√ºk Rapor".
5.  **Pƒ∞YASA ƒ∞≈ûLEMLERƒ∞:** "Devre Kesici", "VBTS", "Kredili ƒ∞≈ülem", "Br√ºt Takas".

====================================================================

A≈ûAMA 2: MADDƒ∞YAT VE B√úY√úKL√úK Fƒ∞LTRESƒ∞ (OLD LITE+ RULES)

Bir haberi "BIG_CONTRACT" (Yeni ƒ∞≈ü) olarak i≈üaretlemek i√ßin ≈üu E≈ûƒ∞KLERƒ∞ a≈ümak ZORUNDADIR:

Durum A: FINANCIALS_JSON VERƒ∞Sƒ∞ VARSA
- (ƒ∞≈ü Tutarƒ± / Yƒ±llƒ±k Ciro [revenue]) > %5 OLMALI.
- VEYA (ƒ∞≈ü Tutarƒ± / Piyasa Deƒüeri [market_cap]) > %3 OLMALI.
- Altƒ±ndaysa -> [] (Alarm Yok).

Durum B: FINANCIALS_JSON VERƒ∞Sƒ∞ YOKSA (K√ñR U√áU≈û)
- Tutar **EN AZ 30.000.000 TL** (veya d√∂viz kar≈üƒ±lƒ±ƒüƒ±) OLMALI.
- 300 Bin TL, 1 Milyon TL, 5 Milyon TL gibi rakamlar REDDET.
- Tutar YOKSA -> REDDET.
- SADECE "Yurt Dƒ±≈üƒ±", "NATO", "Savunma Sanayi" gibi stratejik kelimeler varsa 15 Milyon TL'ye inebilirsin.

- FINANCIALS_JSON null ƒ∞SE:

- Ciro / √∂l√ßek / b√ºy√ºkl√ºk hesabƒ± YAPMA

- Tahmin ETME

- Sadece metin sinyallerine g√∂re ve √áOK SE√áƒ∞Cƒ∞ davran



- Eƒüer metindeki parasal tutar ile FINANCIALS_JSON birlikteyse:

- Oran hesaplayabilirsin:

contract_amount / revenue

contract_amount / market_cap

- Bu oranƒ± key_numbers.ratio alanƒ±na yazabilirsin.


====================================================================

A≈ûAMA 3: GE√áERLƒ∞ ALARM Tƒ∞PLERƒ∞ (POZƒ∞Tƒ∞F Lƒ∞STE)

Sadece a≈üaƒüƒ±daki 4 durumdan biri varsa ve A≈ûAMA 2'yi ge√ßtiyse JSON √ºret:

1.  **BIG_CONTRACT (Dev ƒ∞≈ü Anla≈ümasƒ±):**
    - "ƒ∞mzalandƒ±", "Kazanƒ±ldƒ±" (Kesin Dil).
    - "G√∂r√º≈ü√ºl√ºyor", "Niyet", "Beklenmektedir" -> REDDET.

2.  **CAPITAL_ACTION (Sermaye/Temett√º):**
    - **Bedelsiz:** Oran > %100 VE (YK Kararƒ± veya SPK Onayƒ±).
    - **Temett√º:** Nakit daƒüƒ±tƒ±m kararƒ±.

3.  **CORPORATE_ACTION (Birle≈üme/Satƒ±n Alma):**
    - ≈ûirket SATIN ALIYORSA (B√ºy√ºme odaklƒ±).

4.  **BUYBACK (Geri Alƒ±m):**
    - SADECE "Geri Alƒ±m Programƒ± BA≈ûLATILMASI".
    - G√ºnl√ºk alƒ±m i≈ülemleri -> REDDET.

====================================================================


Dƒ∞NAMƒ∞K FREKANS Fƒ∞LTRESƒ∞ (ADAPTƒ∞F E≈ûƒ∞K)

Sana "NEWS_FREQUENCY_7D" (Son 7 G√ºnl√ºk Haber Sayƒ±sƒ±) verilecek.
Bu sayƒ±ya g√∂re "BIG_CONTRACT" e≈üiklerini sertle≈ütir:

1.  **D√ú≈û√úK FREKANS (0-1 Haber):**
    - ≈ûirket sessizdi, bu haber S√úRPRƒ∞Z olabilir.
    - Standart kurallarƒ± uygula (25 Milyon TL veya %5 Ciro).

2.  **ORTA FREKANS (2-4 Haber):**
    - ≈ûirket aktif. Haber yorgunluƒüu ba≈ülƒ±yor.
    - E≈ûƒ∞ƒûƒ∞ Y√úKSELT: Tutar en az 50 Milyon TL (veya %10 Ciro) olmalƒ±.

3.  **Y√úKSEK FREKANS (5+ Haber):**
    - ≈ûirket "SPAM" yapƒ±yor. Piyasa tepkisizle≈ümi≈ü olabilir.
    - ACIMASIZ OL: Tutar en az 150 Milyon TL (veya %20 Ciro) olmalƒ±.
    - Altƒ±ndaysa -> REDDET ([]).

====================================================================


√áIKTI FORMATI (STRICT JSON)
Emin deƒüilsen, tutar k√º√ß√ºkse, bor√ßlanmaysa -> [] d√∂nd√ºr.

[
  
"ticker": "XXXX",

"published_at": {

"date": "YYYY-MM-DD",

"time": "HH:MM",

"timezone": "Europe/Istanbul"

},

"key_numbers": {

"amount": "string veya null",

"ratio": "string veya null",

"dates": ["string", "..."]

},

"event_type": "CAPITAL_ACTION | BIG_CONTRACT | CORPORATE_ACTION | BUYBACK",

"urgency": "HIGH | VERY_HIGH",

"confidence": 0.95,

"watch_reason": [

"Tutar: 45 Milyon USD",

"Ciroya oran: %18 (√∂l√ßek b√ºy√ºk)",

"Baƒülayƒ±cƒ±lƒ±k: Kesin s√∂zle≈üme"

],

"notification_text": "≈ûirket X, ciroya anlamlƒ± oranlƒ± ve kesinle≈ümi≈ü yurt dƒ±≈üƒ± s√∂zle≈üme a√ßƒ±kladƒ±."

}

]
"""



def setup_gemini():
    if not API_KEY:
        print("Please set the GEMINI_API_KEY environment variable.")
        print("Example: export GEMINI_API_KEY='your_api_key'")
        return None
    
    client = genai.Client(api_key=API_KEY)
    return client

SUBSCRIBERS_FILE = "subscribers.json"

def get_subscribers():
    if not os.path.exists(SUBSCRIBERS_FILE):
        return []
    try:
        with open(SUBSCRIBERS_FILE, 'r') as f:
            return json.load(f)
    except:
        return []

def send_telegram_notification(item, file_name):
    """Sends a detailed notification to all subscribers."""
    if not TELEGRAM_BOT_TOKEN:
        print("[WARN] Telegram Bot Token not set.")
        return

    subscribers = get_subscribers()
    if not subscribers:
        # Fallback to env chat ID if no subscribers file content
        if TELEGRAM_CHAT_ID:
            subscribers = [TELEGRAM_CHAT_ID]
        else:
            print("[WARN] No subscribers found.")
            return

    # Extract fields safely
    ticker = item.get("ticker", "UNKNOWN")
    event_type = item.get("event_type", "UNKNOWN")
    confidence = item.get("confidence", 0.0)
    notif_text = item.get("notification_text", "No text provided.")
    
    # Published At
    pub_at = item.get("published_at", {})
    if isinstance(pub_at, dict):
        date_str = pub_at.get("date", "")
        time_str = pub_at.get("time", "")
    else:
        date_str, time_str = "", ""
    
    # Key Numbers
    key_nums = item.get("key_numbers", {})
    if not isinstance(key_nums, dict): key_nums = {}
    amount = key_nums.get("amount") or "-"
    ratio = key_nums.get("ratio") or "-"
    
    # Watch Reason
    reasons = item.get("watch_reason", [])
    if isinstance(reasons, list):
        reasons_str = "\n".join([f"‚Ä¢ {r}" for r in reasons])
    else:
        reasons_str = str(reasons)

    # Construct HTML Message
    msg = f"""üö® <b>KAP ALARM</b> ({confidence})

<b>Hisse:</b> {ticker}
<b>Tip:</b> {event_type}
<b>Tarih:</b> {date_str} {time_str}

üí∞ <b>Rakamlar:</b>
‚Ä¢ Tutar: {amount}
‚Ä¢ Oran: {ratio}

üìù <b>√ñzet:</b>
{notif_text}

üîç <b>Tespit Nedeni:</b>
{reasons_str}

üìÇ <i>Dosya: {file_name}</i>"""

    url = f"https://api.telegram.org/bot{TELEGRAM_BOT_TOKEN}/sendMessage"
    
    for chat_id in subscribers:
        try:
            payload = {
                "chat_id": chat_id,
                "text": msg,
                "parse_mode": "HTML" # HTML is safer for underscores in filenames
            }
            resp = requests.post(url, json=payload, timeout=5)
            
            if resp.status_code != 200:
                print(f"[ERROR] Failed to send to {chat_id}: {resp.status_code} - {resp.text}")
                
        except Exception as e:
            print(f"[ERROR] Connection failed to {chat_id}: {e}")
    
    print(f"[INFO] Notification process completed for {len(subscribers)} subscribers.")


def extract_symbol_from_gemini_json(data: dict) -> str | None:
    """
    √ñncelik sƒ±rasƒ±:
    1) data['symbol'] / data['ticker']
    2) subject i√ßinde BIST:XXXX / (XXXX) / hisse=XXXX gibi desenler
    3) summary/fullText i√ßinde BIST:XXXX vb.
    """
    # 1) doƒürudan alan
    for k in ("symbol", "ticker", "hisse", "stockCode", "stock_code"):
        v = data.get(k)
        if isinstance(v, str) and v.strip():
            return v.strip().upper()

    # 2) subject/summary/fullText i√ßinden regex
    hay = " ".join([
        str(data.get("subject", "")),
        str(data.get("summary", "")),
        str(data.get("fullText", "")),
    ])

    # yaygƒ±n desenler
    patterns = [
        r"\bBIST[:\s]*([A-Z]{3,6})\b",
        r"\bhisse[:=\s]*([A-Z]{3,6})\b",
        r"\b\(([A-Z]{3,6})\)\b",
        r"\bhisse=([A-Z]{3,6})\b",
    ]
    for p in patterns:
        m = re.search(p, hay, flags=re.IGNORECASE)
        if m:
            return m.group(1).upper()

    return None

def load_financials_for_symbol(symbol: str) -> dict | None:
    """
    ./daily_data_kap/financials/{SYMBOL}_financials.json dosyasƒ±nƒ± okur.
    Yoksa None d√∂nd√ºr√ºr.
    """
    if not symbol:
        return None
    fn = f"{symbol.upper()}_financials.json"
    path = os.path.join(FIN_DIR, fn)
    if not os.path.exists(path):
        return None
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None

def process_file(client, file_path, embedder, memory):  
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        symbol = extract_symbol_from_gemini_json(data)
        fin = load_financials_for_symbol(symbol) if symbol else None

        # published_at vs publishDate (DD.MM.YYYY HH:MM:SS) handling
        pub_at = data.get("published_at")
        
        if not pub_at:
            pdate = data.get("publishDate")
            if pdate:
                try:
                    # Parse "30.12.2025 19:10:53"
                    dt_obj = datetime.strptime(pdate, "%d.%m.%Y %H:%M:%S")
                    # Manually add +03:00 timezone suffix since we assume TR time
                    pub_at = dt_obj.strftime("%Y-%m-%dT%H:%M:%S+03:00")
                except Exception:
                    # Parse hatasƒ± olursa sessizce ge√ß
                    pass

        # Hala yoksa fallback √ºret
        if not pub_at:
            now = datetime.now()
            pub_at = now.strftime("%Y-%m-%dT%H:%M:%S+03:00")

        # ‚úÖ handle_new_kap kap_json.ticker bekliyor -> ekle
        kap_json = {
            "ticker": symbol or "",
            "published_at": pub_at,
            "subject": data.get("subject") or "",
            "summary": data.get("summary") or "",
            "fullText": data.get("fullText") or "",
        }

        # ‚úÖ Retrieval (topK3 + duplicate gate)
        # ‚úÖ Retrieval (topK3 + duplicate gate)
        if symbol and embedder and memory:
            # Import explicitly inside function if simpler, or assume passed objects are valid
            from chroma_kap_memory import handle_new_kap, store_kap # Ensure these are available
            retrieval, store_pack = handle_new_kap(
                embedder, memory, kap_json,
                financials_json=fin,
                topk=3
            )
        else:
            retrieval, store_pack = None, None

      
        

        # ‚úÖ LLM content
        content_parts = []
        content_parts.append(f"SYMBOL: {symbol}" if symbol else "SYMBOL: UNKNOWN")

        if fin:
            content_parts.append("FINANCIALS_JSON:\n" + json.dumps(fin, ensure_ascii=False, indent=2))
        else:
            content_parts.append("FINANCIALS_JSON: null")

        # ‚úÖ HISTORY_CONTEXT_TOPK3
        if retrieval and retrieval.get("TOPK_CONTEXT"):
            hx = []
            for i, h in enumerate(retrieval["TOPK_CONTEXT"], 1):
                hx.append(
                    f"[{i}] published_at={h.get('published_at')} sim={h.get('similarity')}\n"
                    f"{(h.get('text') or '')[:900]}"
                )
            content_parts.append("HISTORY_CONTEXT_TOPK3:\n" + "\n\n".join(hx))
        else:
            content_parts.append("HISTORY_CONTEXT_TOPK3: none")
        # ... (TopK hazƒ±rlandƒ±ktan sonra) ...

        # ‚úÖ FREKANS ANALƒ∞Zƒ∞
        freq_7d = 0
        if symbol and MEMORY:
            # Memory global veya parametre olarak gelmeli
            freq_7d = get_ticker_frequency(MEMORY, symbol, days=7)

        # Prompta ekle
        content_parts.append(f"NEWS_FREQUENCY_7D: {freq_7d} (Son 7 g√ºnde bu ≈üirketten gelen haber sayƒ±sƒ±)")
        # KAP metni
        if kap_json["subject"]:
            content_parts.append(f"Subject: {kap_json['subject']}")
        if kap_json["summary"]:
            content_parts.append(f"Summary: {kap_json['summary']}")
        if kap_json["fullText"]:
            content_parts.append(f"Full Text:\n{kap_json['fullText']}")

        full_content = "\n\n".join(content_parts).strip()
        if not full_content:
            return None

        response = client.models.generate_content(
            model='gemini-3-flash-preview', 
            contents=full_content,
            config=types.GenerateContentConfig(
                system_instruction=SYSTEM_PROMPT,
                temperature=0.0,
                top_p=0.95,
                top_k=40,
                max_output_tokens=8192,
                response_mime_type="application/json",
            )
        )

        # ‚úÖ parse
        if response.text and response.text.strip():
            text = response.text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()

            # ‚úÖ Alarm √ßƒ±ksƒ±n/√ßƒ±kmasƒ±n hafƒ±zaya yaz (√∂nerdiƒüin strateji)
            if store_pack and memory:
                from chroma_kap_memory import store_kap
                store_kap(memory, store_pack)

            return text

        # response bo≈üsa da hafƒ±zaya yaz
        if store_pack and memory:
            from chroma_kap_memory import store_kap
            store_kap(memory, store_pack)

        return None

    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        return None


def main():
    print("Initializing Gemini KAP Analyzer...")
    
    # 1. Setup Client
    client = setup_gemini()
    if not client:
        return

    # 2. Lazy Load Embedder & Memory
    print("[INFO] Importing chroma_kap_memory persistence module...")
    from chroma_kap_memory import load_embedder, KapMemory

    print("[INFO] Loading embedding model (BGE-M3)... This may take a moment.")
    start_t = time.time()
    EMBEDDER = load_embedder("BAAI/bge-m3")
    print(f"[INFO] Model loaded in {time.time() - start_t:.2f}s")

    print("[INFO] Connecting to Vector Memory...")
    MEMORY = KapMemory(persist_dir="./chroma_kap_memory", collection_name="kap_memory")

    print("=" * 80)
    print("GEMINI KAP ANALYZER - S√úREKLƒ∞ ƒ∞ZLEME MODU")
    print("=" * 80)
    
    # Load existing alarms to persist history and fix NameError
    alarms = []
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                alarms = json.load(f)
            print(f"[INFO] Ge√ßmi≈ü {len(alarms)} alarm y√ºklendi.")
        except Exception as e:
            print(f"[WARN] Ge√ßmi≈ü alarmlar y√ºklenemedi: {e}")
            alarms = []

    # Track processed files to avoid re-analysis
    processed_files = set()
    
    # Load processed files from persistent storage
    if os.path.exists(PROCESSED_TRACKER_FILE):
        try:
            with open(PROCESSED_TRACKER_FILE, 'r') as f:
                processed_files = set(json.load(f))
            print(f"[INFO] {len(processed_files)} i≈ülenmi≈ü dosya ge√ßmi≈üten y√ºklendi.")
        except Exception as e:
            print(f"[WARN] ƒ∞≈ülenmi≈ü dosya listesi y√ºklenemedi: {e}")
            processed_files = set()
    
    # Also ignore files that generated alarms previously (just in case they are not in tracker)
    for alarm in alarms:
        if "_source_file" in alarm:
            processed_files.add(alarm["_source_file"])
    
    
    while True:
        try:
            # Find files
            # Walking through the gemini directory structure: gemini/*_gemini.json
            search_pattern = os.path.join(DATA_DIR, "*_gemini.json")
            files = glob.glob(search_pattern)
            
            new_files = [f for f in files if f not in processed_files]
            
            if new_files:
                print(f"\n[{datetime.now().strftime('%H:%M:%S')}] {len(new_files)} analiz edilmemi≈ü dosya bulundu.")
                
                for i, file_path in enumerate(new_files):
                    print(f"Processing [{i+1}/{len(new_files)}]: {os.path.basename(file_path)}")
                    
                    result_json_str = process_file(client, file_path, EMBEDDER, MEMORY)
                    
                    # Mark as processed immediately (even if failed/empty response) to avoid death loops
                    processed_files.add(file_path)
                    
                    # Save tracker periodically (every file is safer for crashes)
                    try:
                        with open(PROCESSED_TRACKER_FILE, 'w') as f:
                            json.dump(list(processed_files), f)
                    except:
                        pass
                    
                    if result_json_str:
                        try:
                            result_data = json.loads(result_json_str)
                            
                            # Normalize to a list of items
                            items_to_process = []
                            if isinstance(result_data, list):
                                items_to_process = result_data
                            elif isinstance(result_data, dict):
                                items_to_process = [result_data]
                            
                            for item in items_to_process:
                                confidence = item.get("confidence", 0.0) if isinstance(item, dict) else 0.0
                                
                                if isinstance(item, dict) and confidence >= 0.95:
                                    print(f"ALARM DETECTED in {os.path.basename(file_path)}! (Confidence: {confidence})")
                                    item["_source_file"] = file_path 
                                    alarms.append(item)
                                    
                                    # Save immediately
                                    try:
                                        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                                            json.dump(alarms, f, ensure_ascii=False, indent=2)
                                    except Exception as e:
                                        print(f"Error saving alarms file: {e}")
                                    
                                    # Send Telegram Notification
                                    send_telegram_notification(item, os.path.basename(file_path))

                                elif isinstance(item, dict):
                                     print(f"Low confidence ({confidence}) in {os.path.basename(file_path)}. Skipped.")

                        except json.JSONDecodeError:
                            print(f"Failed to decode JSON in {os.path.basename(file_path)}")
                            # print(f"Raw response: {result_json_str[:200]}...") # Optional debug
                            pass
                    
                    # Mark as processed handled above
                    # processed_files.add(file_path)
                    
                    # Sleep to respect rate limits
                    time.sleep(4) 
            
            else:
                # No new files
                # print(".", end="", flush=True) 
                time.sleep(10) # Wait 10 seconds before next scan

        except Exception as e:
            print(f"\n[ERROR] Watch loop error: {e}")
            time.sleep(10)

if __name__ == "__main__":
    main()
